{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea2e03-6805-4ee9-8b2a-f547b933c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096c05c-c6fb-4894-826d-249f43eb578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_seasons = pd.read_csv('./data/processed/team_season_features.csv')\n",
    "print(team_seasons.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686f63a-546d-42a7-87fd-ab2aa5efe919",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_tourney_matchups = pd.read_csv('./data/raw/mens/MNCAATourneyCompactResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b225b9d-44f9-46d6-bd9a-ec57a94a73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(team_seasons.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676addd3-e983-49b1-b533-7c303c5073d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter tournament games from 2003 onwards\n",
    "tourney_games = previous_tourney_matchups[previous_tourney_matchups['Season'] >= 2003].copy()\n",
    "print(f\"Number of tournament games from 2003 onwards: {len(tourney_games)}\")\n",
    "\n",
    "# Step 2: Randomize team assignment\n",
    "def randomize_teams(df):\n",
    "    \"\"\"\n",
    "    Randomly assign teams as TeamA and TeamB to avoid bias in the prediction model.\n",
    "    Returns a dataframe with TeamA/TeamB IDs and a binary target indicating if TeamA won.\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Create arrays to store the randomized teams and outcome\n",
    "    teamA_ids = []\n",
    "    teamB_ids = []\n",
    "    teamA_scores = []\n",
    "    teamB_scores = []\n",
    "    teamA_won = []\n",
    "    \n",
    "    # For each game, randomly decide which team is A and which is B\n",
    "    for _, game in df.iterrows():\n",
    "        # Randomly decide if winner is TeamA (coin flip)\n",
    "        if random.random() < 0.5:\n",
    "            # Winner is TeamA\n",
    "            teamA_ids.append(game['WTeamID'])\n",
    "            teamB_ids.append(game['LTeamID'])\n",
    "            teamA_scores.append(game['WScore'])\n",
    "            teamB_scores.append(game['LScore'])\n",
    "            teamA_won.append(1)  # TeamA won\n",
    "        else:\n",
    "            # Winner is TeamB\n",
    "            teamA_ids.append(game['LTeamID'])\n",
    "            teamB_ids.append(game['WTeamID'])\n",
    "            teamA_scores.append(game['LScore'])\n",
    "            teamB_scores.append(game['WScore'])\n",
    "            teamA_won.append(0)  # TeamB won\n",
    "    \n",
    "    # Add the new columns to the dataframe\n",
    "    result_df['TeamAID'] = teamA_ids\n",
    "    result_df['TeamBID'] = teamB_ids\n",
    "    result_df['TeamAScore'] = teamA_scores\n",
    "    result_df['TeamBScore'] = teamB_scores\n",
    "    result_df['TeamA_Won'] = teamA_won\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    columns_to_keep = ['Season', 'DayNum', 'TeamAID', 'TeamBID', \n",
    "                       'TeamAScore', 'TeamBScore', 'TeamA_Won', 'WLoc', 'NumOT']\n",
    "    return result_df[columns_to_keep]\n",
    "\n",
    "# Apply the randomization\n",
    "randomized_games = randomize_teams(tourney_games)\n",
    "print(\"\\nFirst few rows of randomized games:\")\n",
    "print(randomized_games.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7b6de-2970-4f08-b905-5c2b23b9dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge team season statistics for both teams\n",
    "def add_team_features(games_df, stats_df):\n",
    "    \"\"\"\n",
    "    Add team season statistics for both TeamA and TeamB.\n",
    "    \"\"\"\n",
    "    # First, join TeamA features\n",
    "    merged_df = games_df.merge(\n",
    "        stats_df,\n",
    "        left_on=['Season', 'TeamAID'],\n",
    "        right_on=['Season', 'TeamID'],\n",
    "        how='left',\n",
    "        suffixes=('', '_drop')\n",
    "    )\n",
    "    \n",
    "    # Drop duplicate columns and rename columns with TeamA prefix\n",
    "    teamA_cols = [col for col in merged_df.columns if col not in games_df.columns and not col.endswith('_drop')]\n",
    "    for col in teamA_cols:\n",
    "        merged_df.rename(columns={col: f'TeamA_{col}'}, inplace=True)\n",
    "    \n",
    "    # Drop columns with _drop suffix\n",
    "    merged_df = merged_df.drop([col for col in merged_df.columns if col.endswith('_drop')], axis=1)\n",
    "    \n",
    "    # Then, join TeamB features\n",
    "    merged_df = merged_df.merge(\n",
    "        stats_df,\n",
    "        left_on=['Season', 'TeamBID'],\n",
    "        right_on=['Season', 'TeamID'],\n",
    "        how='left',\n",
    "        suffixes=('', '_drop')\n",
    "    )\n",
    "    \n",
    "    # Drop duplicate columns and rename columns with TeamB prefix\n",
    "    teamB_cols = [col for col in merged_df.columns if col not in games_df.columns \n",
    "                 and not col.endswith('_drop') \n",
    "                 and not col.startswith('TeamA_') \n",
    "                 and col != 'TeamID']\n",
    "    for col in teamB_cols:\n",
    "        merged_df.rename(columns={col: f'TeamB_{col}'}, inplace=True)\n",
    "    \n",
    "    # Drop columns with _drop suffix and TeamID column\n",
    "    merged_df = merged_df.drop([col for col in merged_df.columns if col.endswith('_drop') or col == 'TeamID'], axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Apply the team feature merging\n",
    "final_dataset = add_team_features(randomized_games, team_seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d4aed-63cc-4766-9629-92608d41d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape and a sample of the final dataset\n",
    "print(f\"\\nFinal dataset shape: {final_dataset.shape}\")\n",
    "print(\"\\nSample of final dataset columns:\")\n",
    "print(final_dataset.columns[:10].tolist() + ['...'] + final_dataset.columns[-10:].tolist())\n",
    "print(\"\\nFirst 3 rows of the final dataset (first few columns):\")\n",
    "print(final_dataset[['Season', 'DayNum', 'TeamAID', 'TeamBID', 'TeamA_Won', 'TeamAScore', 'TeamBScore']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d53aa4-6ec8-4c3a-a4d4-0e85e3c0b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb807c5-32fe-4b71-ab0d-b0c2eb1e1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Identify winning team features for each game\n",
    "def get_winning_team_features(dataset):\n",
    "    winning_features = []\n",
    "    \n",
    "    for idx, row in dataset.iterrows():\n",
    "        # Extract all feature columns (excluding metadata)\n",
    "        team_a_cols = [col for col in dataset.columns if col.startswith('TeamA_') and col != 'TeamA_Won']\n",
    "        team_b_cols = [col for col in dataset.columns if col.startswith('TeamB_')]\n",
    "        \n",
    "        # Create a dictionary to hold winning team features\n",
    "        winning_data = {}\n",
    "        \n",
    "        # Determine which team won and get their features\n",
    "        if row['TeamA_Won'] == 1:\n",
    "            # TeamA won\n",
    "            for col in team_a_cols:\n",
    "                feature_name = col.replace('TeamA_', '')\n",
    "                winning_data[feature_name] = row[col]\n",
    "        else:\n",
    "            # TeamB won\n",
    "            for col in team_b_cols:\n",
    "                feature_name = col.replace('TeamB_', '')\n",
    "                winning_data[feature_name] = row[col]\n",
    "        \n",
    "        # Add season and game ID for reference\n",
    "        winning_data['Season'] = row['Season']\n",
    "        winning_data['GameID'] = idx\n",
    "        \n",
    "        winning_features.append(winning_data)\n",
    "    \n",
    "    return pd.DataFrame(winning_features)\n",
    "\n",
    "# Get winning team features\n",
    "winning_teams_df = get_winning_team_features(final_dataset)\n",
    "\n",
    "# Display basic statistics for the winning teams\n",
    "print(f\"Shape of winning teams dataset: {winning_teams_df.shape}\")\n",
    "print(\"\\nSummary statistics for winning teams:\")\n",
    "print(winning_teams_df.describe().T[['mean', 'std', 'min', 'max']].head(10))\n",
    "\n",
    "# Select numerical features for correlation analysis\n",
    "# Exclude categorical/text features and identifiers\n",
    "numerical_features = winning_teams_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_features = [col for col in numerical_features if col not in ['Season', 'GameID', 'TeamID']]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = winning_teams_df[numerical_features].corr()\n",
    "\n",
    "# Create a more readable subset by filtering strong correlations\n",
    "# Keep correlations with absolute value above threshold\n",
    "threshold = 0.3\n",
    "filtered_corr = correlation_matrix.abs()\n",
    "filtered_corr = filtered_corr.where(filtered_corr > threshold, np.nan)\n",
    "\n",
    "# Create heatmap figure\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "           xticklabels=True, yticklabels=True)\n",
    "plt.title('Correlation Heatmap for Winning Teams\\' Features', fontsize=16)\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a filtered heatmap for stronger correlations\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(filtered_corr, annot=False, cmap='coolwarm', center=0, \n",
    "           xticklabels=True, yticklabels=True)\n",
    "plt.title('Filtered Correlation Heatmap (|r| > 0.3) for Winning Teams\\' Features', fontsize=16)\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Let's also identify the top pairs of highly correlated features\n",
    "corr_pairs = []\n",
    "for i in range(len(numerical_features)):\n",
    "    for j in range(i+1, len(numerical_features)):\n",
    "        feature1 = numerical_features[i]\n",
    "        feature2 = numerical_features[j]\n",
    "        corr_value = correlation_matrix.loc[feature1, feature2]\n",
    "        if abs(corr_value) > 0.7:  # Strong correlation threshold\n",
    "            corr_pairs.append((feature1, feature2, corr_value))\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "# Display top correlated pairs\n",
    "print(\"\\nTop 15 strongly correlated feature pairs:\")\n",
    "for feature1, feature2, corr in corr_pairs[:15]:\n",
    "    print(f\"{feature1} and {feature2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e2d06-f53c-459f-ad8b-9e4a12a8e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Create a dataset that pairs winning and losing team features for direct comparison\n",
    "def create_comparison_dataset(dataset):\n",
    "    comparisons = []\n",
    "    \n",
    "    # Get all TeamA and TeamB columns\n",
    "    teamA_cols = [col for col in dataset.columns if col.startswith('TeamA_') and col != 'TeamA_Won']\n",
    "    teamB_cols = [col for col in dataset.columns if col.startswith('TeamB_')]\n",
    "    \n",
    "    # Extract feature names and make sure they exist for both teams\n",
    "    teamA_features = [col.replace('TeamA_', '') for col in teamA_cols]\n",
    "    teamB_features = [col.replace('TeamB_', '') for col in teamB_cols]\n",
    "    \n",
    "    # Find common features that exist for both TeamA and TeamB\n",
    "    common_features = set(teamA_features).intersection(set(teamB_features))\n",
    "    \n",
    "    print(f\"Found {len(common_features)} common features to compare\")\n",
    "    \n",
    "    # Identify which features are numeric\n",
    "    numeric_features = []\n",
    "    non_numeric_features = []\n",
    "    \n",
    "    for feature in common_features:\n",
    "        if np.issubdtype(dataset[f'TeamA_{feature}'].dtype, np.number):\n",
    "            numeric_features.append(feature)\n",
    "        else:\n",
    "            non_numeric_features.append(feature)\n",
    "    \n",
    "    print(f\"Numeric features: {len(numeric_features)}\")\n",
    "    print(f\"Non-numeric features: {len(non_numeric_features)}\")\n",
    "    \n",
    "    for idx, row in dataset.iterrows():\n",
    "        # Determine which team won\n",
    "        if row['TeamA_Won'] == 1:\n",
    "            winning_prefix = 'TeamA_'\n",
    "            losing_prefix = 'TeamB_'\n",
    "        else:\n",
    "            winning_prefix = 'TeamB_'\n",
    "            losing_prefix = 'TeamA_'\n",
    "        \n",
    "        # Create a record for this game\n",
    "        game_data = {\n",
    "            'Season': row['Season'],\n",
    "            'DayNum': row['DayNum'],\n",
    "            'GameID': idx\n",
    "        }\n",
    "        \n",
    "        # Process numeric features with difference calculation\n",
    "        for feature in numeric_features:\n",
    "            winner_val = row[f'{winning_prefix}{feature}']\n",
    "            loser_val = row[f'{losing_prefix}{feature}']\n",
    "            \n",
    "            # Add winning and losing team values\n",
    "            game_data[f'Winner_{feature}'] = winner_val\n",
    "            game_data[f'Loser_{feature}'] = loser_val\n",
    "            \n",
    "            # Calculate the difference only for numeric features\n",
    "            game_data[f'Diff_{feature}'] = winner_val - loser_val\n",
    "        \n",
    "        # Process non-numeric features (just store them without calculating difference)\n",
    "        for feature in non_numeric_features:\n",
    "            game_data[f'Winner_{feature}'] = row[f'{winning_prefix}{feature}']\n",
    "            game_data[f'Loser_{feature}'] = row[f'{losing_prefix}{feature}']\n",
    "            # No difference calculation for non-numeric features\n",
    "        \n",
    "        comparisons.append(game_data)\n",
    "    \n",
    "    return pd.DataFrame(comparisons)\n",
    "\n",
    "# Create the comparison dataset\n",
    "comparison_df = create_comparison_dataset(final_dataset)\n",
    "\n",
    "# Identify numerical features to analyze\n",
    "diff_columns = [col for col in comparison_df.columns if col.startswith('Diff_')]\n",
    "feature_names = [col.replace('Diff_', '') for col in diff_columns]\n",
    "\n",
    "# Calculate statistical significance and effect size for each feature\n",
    "analysis_results = []\n",
    "\n",
    "for feature in feature_names:\n",
    "    winner_values = comparison_df[f'Winner_{feature}']\n",
    "    loser_values = comparison_df[f'Loser_{feature}']\n",
    "    \n",
    "    # Skip any remaining non-numeric features\n",
    "    if not np.issubdtype(winner_values.dtype, np.number):\n",
    "        continue\n",
    "        \n",
    "    # Calculate mean difference\n",
    "    mean_diff = winner_values.mean() - loser_values.mean()\n",
    "    \n",
    "    # Perform t-test for statistical significance\n",
    "    t_stat, p_value = stats.ttest_ind(\n",
    "        winner_values.dropna(), \n",
    "        loser_values.dropna(), \n",
    "        equal_var=False\n",
    "    )\n",
    "    \n",
    "    # Calculate effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt((winner_values.std()**2 + loser_values.std()**2) / 2)\n",
    "    effect_size = mean_diff / pooled_std if pooled_std != 0 else 0\n",
    "    \n",
    "    # Store results\n",
    "    analysis_results.append({\n",
    "        'Feature': feature,\n",
    "        'Winner_Mean': winner_values.mean(),\n",
    "        'Loser_Mean': loser_values.mean(),\n",
    "        'Mean_Difference': mean_diff,\n",
    "        'Percent_Difference': (mean_diff / loser_values.mean() * 100) if loser_values.mean() != 0 else np.nan,\n",
    "        'T_Statistic': t_stat,\n",
    "        'P_Value': p_value,\n",
    "        'Effect_Size': effect_size,\n",
    "        'Is_Significant': p_value < 0.05\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort by effect size\n",
    "results_df = pd.DataFrame(analysis_results)\n",
    "results_df = results_df.sort_values('Effect_Size', ascending=False)\n",
    "\n",
    "# Print the top 15 most indicative features (based on effect size)\n",
    "print(\"Top 15 Statistics Most Indicative of Winning Teams (largest effect sizes):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(results_df.head(15))\n",
    "\n",
    "# Visualize the top 10 most indicative features\n",
    "top_features = results_df.head(10)['Feature'].tolist()\n",
    "\n",
    "# Create a bar chart of effect sizes for top features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_results = results_df.head(15).copy()\n",
    "# Clean up feature names for display\n",
    "top_results['Feature'] = top_results['Feature'].str.replace('_', ' ')\n",
    "\n",
    "sns.barplot(x='Effect_Size', y='Feature', data=top_results, palette='viridis')\n",
    "plt.title('Effect Size of Top 15 Features (Winners vs. Losers)', fontsize=14)\n",
    "plt.xlabel('Effect Size (Cohen\\'s d)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for the top 5 features\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(top_features[:5]):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    \n",
    "    # Create boxplot with swarmplot overlay\n",
    "    data = pd.DataFrame({\n",
    "        'value': pd.concat([comparison_df[f'Winner_{feature}'], comparison_df[f'Loser_{feature}']]),\n",
    "        'group': ['Winners'] * len(comparison_df) + ['Losers'] * len(comparison_df)\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(x='group', y='value', data=data)\n",
    "    plt.title(f\"{feature.replace('_', ' ')}\")\n",
    "    plt.xlabel('')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparison of Winners vs. Losers: Top 5 Most Indicative Features', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06c67a-4d58-4ff1-94e9-e8e3daa1c107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
